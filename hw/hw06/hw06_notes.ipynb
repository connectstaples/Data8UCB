{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06, Prof Sanchez \n",
    "## Notes\n",
    "### Sean Villegas\n",
    "_Main goal is to get stuck document thinking and what was the correct solution with examples_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flu Shot Example for creating a test statistic \n",
    "- Data: Shot A = 120, Shot B = 80, total = 200, observed percent Shot A = 60%.\n",
    "- Dr. Smith: “Fair coin, P(Shot A) = 50%.”\n",
    "- Dr. Jones: “Not a fair coin, not random.”\n",
    "- Null: P(Shot A) = 0.5 (Dr. Smith); based on chance.\n",
    "- Alternative: P(Shot A) ≠ 0.5 (Dr. Jones); not based on chance, its based on something else like datat \n",
    "\n",
    "**Options to choose from**\n",
    "- percent of Shot A - 50.\n",
    "- |percent of Shot A - 50|. # Abs \n",
    "- percent of Shot A - 60.\n",
    "- |percent of Shot A - 60| # Abs\n",
    " \n",
    "\n",
    " **TVD Formula**\n",
    " - 1/2(|probability p| + |probability q|)\n",
    " - _gives us the distance between the two proportions, it is also the distance between the two proportions P and Q_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "v1 = abs(211/318)\n",
    "v2 = abs(107/318)\n",
    "v1_v2 = v1 + v2\n",
    "tvd = (v1_v2 * 0.5)\n",
    "print(tvd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Chapter 11.3](https://inferentialthinking.com/chapters/11/3/Decisions_and_Uncertainty.html#step-1-the-hypotheses)**\n",
    "\n",
    "Notes:\n",
    "- Hypothesis Testing (11.3): You simulate under the null to see if the observed statistic fits. P-value = proportion of simulated stats as extreme as observed.\n",
    "\n",
    "Flu Shot Clinic Scenario: \n",
    "- Data: Shot A = 120, Shot B = 80, total = 200, observed percent = 60%. # rounded \n",
    "- Null Hypothesis: P(Shot A) = 0.6 (60%, Dr. Smith says it’s a coin with P = 0.6).\n",
    "- Alternative Hypothesis: P(Shot A) ≠ 0.6 (Dr. Jones says it’s not random).\n",
    "- Test Statistic: | percent of Shot A - 60 |\n",
    "- Observed Statistic: 60 - 60 = 0 (real data value).\n",
    "\n",
    "**Objective** \n",
    "- Simulate the test statistic to perform the hypothesis test (e.g., find a p-value).\n",
    "    - **This is how hypothesis tests work in Data 8 (Chapter 11.3)—simulate under null to get a p-value.**\n",
    "<center>Question: What assumption do we need to make to run this simulation?</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.50000000000001\n",
      "64.0\n",
      "57.99999999999999\n",
      "56.00000000000001\n",
      "65.5\n",
      "61.5\n",
      "62.0\n",
      "61.0\n",
      "64.5\n",
      "62.0\n",
      "58.5\n",
      "54.50000000000001\n",
      "62.5\n",
      "57.49999999999999\n",
      "56.00000000000001\n",
      "52.0\n",
      "60.5\n",
      "55.00000000000001\n",
      "62.5\n",
      "57.99999999999999\n",
      "66.5\n",
      "55.00000000000001\n",
      "57.49999999999999\n",
      "59.5\n",
      "53.5\n",
      "58.5\n",
      "56.49999999999999\n",
      "62.5\n",
      "56.49999999999999\n",
      "63.5\n",
      "63.0\n",
      "62.5\n",
      "55.00000000000001\n",
      "58.5\n",
      "59.5\n",
      "54.50000000000001\n",
      "56.00000000000001\n",
      "61.0\n",
      "55.50000000000001\n",
      "62.5\n",
      "61.0\n",
      "63.0\n",
      "56.99999999999999\n",
      "64.5\n",
      "66.5\n",
      "62.0\n",
      "62.0\n",
      "56.00000000000001\n",
      "56.00000000000001\n",
      "62.0\n",
      "66.0\n",
      "64.0\n",
      "56.49999999999999\n",
      "53.0\n",
      "60.5\n",
      "58.5\n",
      "59.5\n",
      "64.5\n",
      "60.5\n",
      "60.5\n",
      "54.50000000000001\n",
      "60.5\n",
      "64.0\n",
      "59.0\n",
      "60.0\n",
      "65.0\n",
      "60.5\n",
      "57.99999999999999\n",
      "59.5\n",
      "63.5\n",
      "59.0\n",
      "56.00000000000001\n",
      "56.99999999999999\n",
      "67.0\n",
      "63.0\n",
      "59.5\n",
      "55.00000000000001\n",
      "60.0\n",
      "60.0\n",
      "63.5\n",
      "61.5\n",
      "63.0\n",
      "62.0\n",
      "63.5\n",
      "60.0\n",
      "53.5\n",
      "56.00000000000001\n",
      "60.0\n",
      "59.5\n",
      "60.0\n",
      "64.5\n",
      "65.0\n",
      "55.00000000000001\n",
      "60.5\n",
      "53.5\n",
      "56.99999999999999\n",
      "59.5\n",
      "59.0\n",
      "64.5\n",
      "59.0\n",
      "56.49999999999999\n",
      "59.0\n",
      "62.5\n",
      "56.99999999999999\n",
      "54.50000000000001\n",
      "64.5\n",
      "57.99999999999999\n",
      "55.50000000000001\n",
      "57.99999999999999\n",
      "55.50000000000001\n",
      "57.49999999999999\n",
      "58.5\n",
      "56.99999999999999\n",
      "57.99999999999999\n",
      "59.5\n",
      "62.0\n",
      "57.49999999999999\n",
      "59.0\n",
      "64.0\n",
      "55.00000000000001\n",
      "57.49999999999999\n",
      "62.5\n",
      "61.0\n",
      "59.0\n",
      "56.49999999999999\n",
      "53.0\n",
      "59.5\n",
      "56.49999999999999\n",
      "64.5\n",
      "58.5\n",
      "63.0\n",
      "59.0\n",
      "52.5\n",
      "55.50000000000001\n",
      "61.5\n",
      "60.5\n",
      "60.5\n",
      "61.5\n",
      "64.5\n",
      "63.0\n",
      "62.5\n",
      "60.0\n",
      "67.5\n",
      "60.5\n",
      "59.0\n",
      "56.99999999999999\n",
      "60.0\n",
      "62.0\n",
      "59.5\n",
      "62.5\n",
      "59.0\n",
      "63.0\n",
      "62.5\n",
      "60.0\n",
      "59.5\n",
      "62.0\n",
      "62.5\n",
      "65.5\n",
      "63.5\n",
      "58.5\n",
      "58.5\n",
      "55.00000000000001\n",
      "57.49999999999999\n",
      "57.99999999999999\n",
      "57.49999999999999\n",
      "57.99999999999999\n",
      "63.0\n",
      "59.5\n",
      "64.0\n",
      "64.5\n",
      "61.5\n",
      "56.99999999999999\n",
      "61.0\n",
      "60.5\n",
      "64.5\n",
      "67.5\n",
      "62.0\n",
      "58.5\n",
      "63.0\n",
      "57.99999999999999\n",
      "62.5\n",
      "60.0\n",
      "61.0\n",
      "60.0\n",
      "58.5\n",
      "64.0\n",
      "55.00000000000001\n",
      "62.0\n",
      "61.0\n",
      "61.0\n",
      "59.5\n",
      "57.99999999999999\n",
      "56.49999999999999\n",
      "62.0\n",
      "67.0\n",
      "61.0\n",
      "62.0\n",
      "59.5\n",
      "62.5\n",
      "60.0\n",
      "61.0\n",
      "60.0\n",
      "62.0\n",
      "64.5\n",
      "64.5\n",
      "67.0\n",
      "62.0\n",
      "56.99999999999999\n",
      "55.00000000000001\n",
      "60.5\n",
      "59.5\n",
      "58.5\n",
      "58.5\n",
      "56.99999999999999\n",
      "58.5\n",
      "61.5\n",
      "60.5\n",
      "65.5\n",
      "57.99999999999999\n",
      "61.5\n",
      "61.0\n",
      "57.49999999999999\n",
      "54.0\n",
      "57.49999999999999\n",
      "64.5\n",
      "57.49999999999999\n",
      "55.00000000000001\n",
      "60.5\n",
      "67.5\n",
      "56.49999999999999\n",
      "61.5\n",
      "56.00000000000001\n",
      "56.99999999999999\n",
      "63.0\n",
      "63.0\n",
      "62.5\n",
      "56.99999999999999\n",
      "59.0\n",
      "56.99999999999999\n",
      "62.0\n",
      "72.5\n",
      "64.5\n",
      "60.0\n",
      "56.00000000000001\n",
      "62.5\n",
      "63.0\n",
      "60.0\n",
      "57.49999999999999\n",
      "59.0\n",
      "64.5\n",
      "59.0\n",
      "57.49999999999999\n",
      "63.5\n",
      "56.99999999999999\n",
      "64.0\n",
      "61.0\n",
      "62.0\n",
      "55.50000000000001\n",
      "50.0\n",
      "60.0\n",
      "56.49999999999999\n",
      "60.0\n",
      "53.0\n",
      "62.5\n",
      "55.00000000000001\n",
      "62.5\n",
      "60.5\n",
      "64.0\n",
      "57.49999999999999\n",
      "61.0\n",
      "62.5\n",
      "61.0\n",
      "67.5\n",
      "59.0\n",
      "61.5\n",
      "54.50000000000001\n",
      "57.99999999999999\n",
      "64.0\n",
      "55.00000000000001\n",
      "66.5\n",
      "57.99999999999999\n",
      "65.5\n",
      "59.0\n",
      "65.0\n",
      "63.5\n",
      "56.99999999999999\n",
      "57.99999999999999\n",
      "58.5\n",
      "60.5\n",
      "61.5\n",
      "60.5\n",
      "56.99999999999999\n",
      "57.49999999999999\n",
      "61.5\n",
      "61.0\n",
      "57.99999999999999\n",
      "57.49999999999999\n",
      "64.0\n",
      "60.0\n",
      "64.0\n",
      "59.0\n",
      "57.99999999999999\n",
      "60.0\n",
      "59.0\n",
      "55.50000000000001\n",
      "58.5\n",
      "55.50000000000001\n",
      "59.5\n",
      "65.0\n",
      "64.5\n",
      "62.5\n",
      "61.5\n",
      "62.5\n",
      "56.00000000000001\n",
      "56.99999999999999\n",
      "59.0\n",
      "60.0\n",
      "63.5\n",
      "64.0\n",
      "56.00000000000001\n",
      "56.99999999999999\n",
      "61.5\n",
      "55.00000000000001\n",
      "54.50000000000001\n",
      "57.49999999999999\n",
      "58.5\n",
      "58.5\n",
      "62.0\n",
      "54.50000000000001\n",
      "55.50000000000001\n",
      "58.5\n",
      "62.0\n",
      "61.5\n",
      "64.5\n",
      "56.99999999999999\n",
      "68.5\n",
      "55.00000000000001\n",
      "49.5\n",
      "55.00000000000001\n",
      "56.99999999999999\n",
      "57.99999999999999\n",
      "57.49999999999999\n",
      "64.0\n",
      "60.0\n",
      "65.5\n",
      "57.99999999999999\n",
      "59.5\n",
      "59.5\n",
      "57.99999999999999\n",
      "65.0\n",
      "59.5\n",
      "53.0\n",
      "58.5\n",
      "62.0\n",
      "63.5\n",
      "64.5\n",
      "59.0\n",
      "59.5\n",
      "58.5\n",
      "66.5\n",
      "59.5\n",
      "65.0\n",
      "60.5\n",
      "60.0\n",
      "66.0\n",
      "65.0\n",
      "62.0\n",
      "59.5\n",
      "62.0\n",
      "56.49999999999999\n",
      "60.5\n",
      "53.0\n",
      "62.0\n",
      "62.0\n",
      "58.5\n",
      "59.5\n",
      "56.00000000000001\n",
      "59.5\n",
      "57.49999999999999\n",
      "57.49999999999999\n",
      "59.5\n",
      "64.0\n",
      "62.0\n",
      "56.00000000000001\n",
      "56.00000000000001\n",
      "53.0\n",
      "56.49999999999999\n",
      "59.5\n",
      "63.0\n",
      "56.00000000000001\n",
      "56.99999999999999\n",
      "67.5\n",
      "55.00000000000001\n",
      "59.0\n",
      "61.5\n",
      "54.50000000000001\n",
      "57.49999999999999\n",
      "64.5\n",
      "62.0\n",
      "55.50000000000001\n",
      "64.5\n",
      "60.5\n",
      "56.00000000000001\n",
      "59.5\n",
      "62.5\n",
      "55.00000000000001\n",
      "68.5\n",
      "62.0\n",
      "55.00000000000001\n",
      "54.0\n",
      "60.0\n",
      "62.5\n",
      "61.5\n",
      "61.0\n",
      "60.5\n",
      "57.49999999999999\n",
      "61.5\n",
      "59.5\n",
      "54.0\n",
      "62.0\n",
      "64.0\n",
      "56.99999999999999\n",
      "59.0\n",
      "60.5\n",
      "54.50000000000001\n",
      "56.00000000000001\n",
      "61.0\n",
      "53.0\n",
      "63.0\n",
      "60.5\n",
      "59.0\n",
      "60.5\n",
      "60.5\n",
      "58.5\n",
      "62.0\n",
      "60.0\n",
      "64.0\n",
      "56.00000000000001\n",
      "57.99999999999999\n",
      "67.0\n",
      "60.0\n",
      "61.0\n",
      "57.99999999999999\n",
      "56.49999999999999\n",
      "61.0\n",
      "61.0\n",
      "61.0\n",
      "55.50000000000001\n",
      "58.5\n",
      "54.0\n",
      "61.5\n",
      "62.0\n",
      "54.0\n",
      "62.5\n",
      "59.5\n",
      "55.50000000000001\n",
      "56.99999999999999\n",
      "62.0\n",
      "63.0\n",
      "61.0\n",
      "62.5\n",
      "63.0\n",
      "56.00000000000001\n",
      "57.99999999999999\n",
      "57.99999999999999\n",
      "71.0\n",
      "60.0\n",
      "59.5\n",
      "65.5\n",
      "60.0\n",
      "60.5\n",
      "61.5\n",
      "63.0\n",
      "60.0\n",
      "64.5\n",
      "61.0\n",
      "62.0\n",
      "57.99999999999999\n",
      "62.5\n",
      "63.0\n",
      "56.99999999999999\n",
      "59.5\n",
      "56.00000000000001\n",
      "63.0\n",
      "60.0\n",
      "57.49999999999999\n",
      "60.5\n",
      "64.0\n",
      "57.99999999999999\n",
      "57.99999999999999\n",
      "67.0\n",
      "63.0\n",
      "59.0\n",
      "54.50000000000001\n",
      "52.5\n",
      "54.50000000000001\n",
      "61.5\n",
      "63.0\n",
      "64.5\n",
      "63.0\n",
      "62.5\n",
      "57.99999999999999\n",
      "61.0\n",
      "57.49999999999999\n",
      "56.49999999999999\n",
      "65.0\n",
      "59.0\n",
      "60.5\n",
      "64.0\n",
      "60.5\n",
      "66.0\n",
      "60.5\n",
      "61.5\n",
      "58.5\n",
      "60.0\n",
      "60.5\n",
      "61.5\n",
      "53.0\n",
      "64.0\n",
      "62.5\n",
      "55.00000000000001\n",
      "59.5\n",
      "59.5\n",
      "61.0\n",
      "55.00000000000001\n",
      "56.49999999999999\n",
      "54.50000000000001\n",
      "61.5\n",
      "65.0\n",
      "60.0\n",
      "62.0\n",
      "58.5\n",
      "63.0\n",
      "56.49999999999999\n",
      "56.49999999999999\n",
      "65.0\n",
      "66.5\n",
      "62.0\n",
      "56.99999999999999\n",
      "54.50000000000001\n",
      "54.0\n",
      "67.5\n",
      "55.00000000000001\n",
      "57.99999999999999\n",
      "60.0\n",
      "52.5\n",
      "60.5\n",
      "65.0\n",
      "56.00000000000001\n",
      "61.0\n",
      "66.5\n",
      "68.5\n",
      "56.49999999999999\n",
      "61.5\n",
      "57.49999999999999\n",
      "63.0\n",
      "60.5\n",
      "59.5\n",
      "60.5\n",
      "63.0\n",
      "62.5\n",
      "62.0\n",
      "54.0\n",
      "55.50000000000001\n",
      "59.0\n",
      "59.0\n",
      "56.49999999999999\n",
      "64.5\n",
      "63.0\n",
      "62.5\n",
      "57.49999999999999\n",
      "57.99999999999999\n",
      "56.49999999999999\n",
      "51.5\n",
      "67.0\n",
      "61.0\n",
      "61.5\n",
      "62.0\n",
      "57.49999999999999\n",
      "56.49999999999999\n",
      "59.0\n",
      "64.5\n",
      "56.49999999999999\n",
      "60.5\n",
      "64.5\n",
      "61.5\n",
      "57.99999999999999\n",
      "53.5\n",
      "58.5\n",
      "63.5\n",
      "61.5\n",
      "61.5\n",
      "58.5\n",
      "65.0\n",
      "63.0\n",
      "57.99999999999999\n",
      "65.5\n",
      "56.99999999999999\n",
      "54.50000000000001\n",
      "66.5\n",
      "56.99999999999999\n",
      "62.0\n",
      "64.0\n",
      "56.00000000000001\n",
      "62.0\n",
      "60.0\n",
      "54.0\n",
      "55.50000000000001\n",
      "62.5\n",
      "56.49999999999999\n",
      "60.0\n",
      "57.99999999999999\n",
      "57.49999999999999\n",
      "62.5\n",
      "59.5\n",
      "62.0\n",
      "56.99999999999999\n",
      "63.5\n",
      "64.5\n",
      "55.50000000000001\n",
      "62.0\n",
      "63.5\n",
      "63.5\n",
      "56.00000000000001\n",
      "62.5\n",
      "58.5\n",
      "60.5\n",
      "62.5\n",
      "66.5\n",
      "53.0\n",
      "55.50000000000001\n",
      "62.0\n",
      "64.0\n",
      "63.0\n",
      "60.5\n",
      "54.0\n",
      "60.0\n",
      "59.5\n",
      "61.0\n",
      "62.0\n",
      "61.0\n",
      "56.00000000000001\n",
      "59.0\n",
      "61.5\n",
      "60.0\n",
      "60.0\n",
      "59.5\n",
      "56.49999999999999\n",
      "63.5\n",
      "63.0\n",
      "57.99999999999999\n",
      "61.0\n",
      "55.50000000000001\n",
      "58.5\n",
      "52.0\n",
      "56.99999999999999\n",
      "56.49999999999999\n",
      "59.0\n",
      "60.0\n",
      "59.5\n",
      "57.49999999999999\n",
      "64.0\n",
      "59.0\n",
      "56.99999999999999\n",
      "65.0\n",
      "57.99999999999999\n",
      "57.49999999999999\n",
      "59.5\n",
      "56.00000000000001\n",
      "59.5\n",
      "64.5\n",
      "64.5\n",
      "61.0\n",
      "62.0\n",
      "57.49999999999999\n",
      "63.0\n",
      "57.99999999999999\n",
      "59.5\n",
      "64.0\n",
      "66.5\n",
      "61.0\n",
      "66.0\n",
      "65.0\n",
      "59.5\n",
      "53.0\n",
      "60.5\n",
      "56.49999999999999\n",
      "60.0\n",
      "56.00000000000001\n",
      "56.99999999999999\n",
      "61.0\n",
      "59.5\n",
      "56.00000000000001\n",
      "61.5\n",
      "59.0\n",
      "64.5\n",
      "61.0\n",
      "58.5\n",
      "59.0\n",
      "59.0\n",
      "61.5\n",
      "60.0\n",
      "61.5\n",
      "60.0\n",
      "60.0\n",
      "65.5\n",
      "67.5\n",
      "56.00000000000001\n",
      "67.5\n",
      "61.0\n",
      "49.5\n",
      "61.0\n",
      "64.0\n",
      "58.5\n",
      "60.5\n",
      "60.5\n",
      "56.49999999999999\n",
      "67.0\n",
      "60.5\n",
      "57.49999999999999\n",
      "61.0\n",
      "62.5\n",
      "64.5\n",
      "60.5\n",
      "62.0\n",
      "58.5\n",
      "59.0\n",
      "63.0\n",
      "54.50000000000001\n",
      "59.5\n",
      "56.49999999999999\n",
      "56.00000000000001\n",
      "61.5\n",
      "68.0\n",
      "56.00000000000001\n",
      "63.5\n",
      "62.5\n",
      "59.0\n",
      "56.99999999999999\n",
      "59.5\n",
      "55.00000000000001\n",
      "59.0\n",
      "55.00000000000001\n",
      "56.00000000000001\n",
      "60.5\n",
      "60.0\n",
      "67.0\n",
      "57.99999999999999\n",
      "60.0\n",
      "57.49999999999999\n",
      "61.5\n",
      "64.0\n",
      "58.5\n",
      "54.50000000000001\n",
      "59.0\n",
      "62.5\n",
      "59.0\n",
      "58.5\n",
      "56.49999999999999\n",
      "59.5\n",
      "64.5\n",
      "61.0\n",
      "61.5\n",
      "62.5\n",
      "59.5\n",
      "65.0\n",
      "57.99999999999999\n",
      "58.5\n",
      "60.5\n",
      "54.50000000000001\n",
      "60.0\n",
      "63.0\n",
      "55.50000000000001\n",
      "63.0\n",
      "56.49999999999999\n",
      "61.0\n",
      "64.5\n",
      "62.0\n",
      "55.00000000000001\n",
      "65.5\n",
      "58.5\n",
      "57.99999999999999\n",
      "56.49999999999999\n",
      "55.50000000000001\n",
      "62.0\n",
      "57.49999999999999\n",
      "59.5\n",
      "60.5\n",
      "58.5\n",
      "63.0\n",
      "63.0\n",
      "57.99999999999999\n",
      "57.99999999999999\n",
      "68.5\n",
      "63.0\n",
      "62.0\n",
      "60.5\n",
      "57.99999999999999\n",
      "56.99999999999999\n",
      "58.5\n",
      "64.0\n",
      "61.5\n",
      "58.5\n",
      "63.0\n",
      "62.0\n",
      "57.99999999999999\n",
      "62.0\n",
      "52.0\n",
      "60.5\n",
      "59.5\n",
      "61.5\n",
      "56.99999999999999\n",
      "56.49999999999999\n",
      "61.5\n",
      "57.49999999999999\n",
      "63.0\n",
      "64.5\n",
      "70.0\n",
      "64.0\n",
      "61.5\n",
      "54.50000000000001\n",
      "59.0\n",
      "61.0\n",
      "56.99999999999999\n",
      "59.5\n",
      "57.99999999999999\n",
      "63.0\n",
      "59.5\n",
      "60.5\n",
      "64.5\n",
      "59.0\n",
      "61.0\n",
      "58.5\n",
      "60.0\n",
      "63.0\n",
      "61.0\n",
      "56.99999999999999\n",
      "56.99999999999999\n",
      "63.0\n",
      "60.5\n",
      "64.0\n",
      "53.0\n",
      "65.5\n",
      "57.49999999999999\n",
      "59.0\n",
      "63.5\n",
      "61.0\n",
      "59.5\n",
      "55.50000000000001\n",
      "59.5\n",
      "57.99999999999999\n",
      "61.0\n",
      "63.0\n",
      "59.0\n",
      "63.0\n",
      "58.5\n",
      "60.5\n",
      "60.5\n",
      "67.5\n",
      "51.5\n",
      "57.49999999999999\n",
      "67.0\n",
      "66.0\n",
      "55.00000000000001\n",
      "57.99999999999999\n",
      "54.50000000000001\n",
      "59.0\n",
      "60.5\n",
      "56.00000000000001\n",
      "58.5\n",
      "57.99999999999999\n",
      "55.50000000000001\n",
      "57.49999999999999\n",
      "56.99999999999999\n",
      "57.49999999999999\n",
      "56.00000000000001\n",
      "58.5\n",
      "62.5\n",
      "61.5\n",
      "63.0\n",
      "61.5\n",
      "63.5\n",
      "62.0\n",
      "60.0\n",
      "56.49999999999999\n",
      "53.5\n",
      "60.5\n",
      "63.0\n",
      "59.0\n",
      "56.99999999999999\n",
      "64.5\n",
      "57.49999999999999\n",
      "55.50000000000001\n",
      "59.5\n",
      "63.0\n",
      "61.0\n",
      "56.49999999999999\n",
      "55.50000000000001\n",
      "57.49999999999999\n",
      "56.49999999999999\n",
      "55.50000000000001\n",
      "62.0\n",
      "57.49999999999999\n",
      "59.5\n",
      "57.99999999999999\n",
      "66.5\n",
      "60.5\n",
      "65.5\n",
      "66.5\n",
      "58.5\n",
      "63.0\n",
      "57.99999999999999\n",
      "65.5\n",
      "62.0\n",
      "67.5\n",
      "55.50000000000001\n",
      "61.0\n",
      "53.5\n",
      "60.0\n",
      "56.49999999999999\n",
      "61.0\n",
      "66.0\n",
      "63.0\n",
      "56.00000000000001\n",
      "65.5\n",
      "68.0\n",
      "61.5\n",
      "60.5\n",
      "56.99999999999999\n",
      "56.49999999999999\n",
      "57.99999999999999\n",
      "57.49999999999999\n",
      "60.5\n",
      "62.0\n",
      "64.0\n",
      "60.0\n",
      "62.5\n",
      "54.50000000000001\n",
      "66.0\n",
      "65.0\n",
      "59.5\n",
      "58.5\n",
      "62.5\n",
      "60.5\n",
      "63.0\n",
      "67.5\n",
      "65.0\n",
      "62.5\n",
      "62.0\n",
      "54.50000000000001\n",
      "61.0\n",
      "65.0\n",
      "61.5\n",
      "64.0\n",
      "61.5\n",
      "56.99999999999999\n",
      "56.49999999999999\n",
      "59.0\n",
      "59.5\n",
      "60.0\n",
      "63.0\n",
      "62.5\n",
      "56.99999999999999\n",
      "56.00000000000001\n",
      "64.0\n",
      "56.49999999999999\n",
      "60.5\n",
      "56.99999999999999\n",
      "60.5\n",
      "51.0\n",
      "60.5\n",
      "56.49999999999999\n",
      "61.5\n",
      "64.5\n",
      "61.5\n",
      "62.5\n",
      "58.5\n",
      "61.5\n",
      "59.0\n",
      "61.0\n",
      "60.5\n",
      "67.5\n",
      "62.5\n",
      "63.0\n",
      "58.5\n",
      "65.0\n",
      "56.49999999999999\n",
      "56.99999999999999\n",
      "63.5\n",
      "62.5\n",
      "54.0\n",
      "64.5\n",
      "53.5\n",
      "60.5\n",
      "63.5\n",
      "54.0\n",
      "55.50000000000001\n",
      "60.5\n",
      "61.0\n",
      "54.0\n",
      "[-4.5  4.  -2.  -4.   5.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou are multiplying by 100 because sample.item(0) represents a proportion (a value between 0 and 1),\\nand you want to express it as a percentage.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datascience import * \n",
    "import numpy as np \n",
    "\n",
    "testing_number = 1000\n",
    "simulations = make_array() \n",
    "\n",
    "for i in range(testing_number):\n",
    "    sample = sample_proportions(200, [3/5, 2/5]) # sample_proportions(<sample size>, [probabilities])\n",
    "    percent = sample.item(0) * 100  # why are we multiplying by 100\n",
    "    print(percent)\n",
    "    stat = percent - 60 \n",
    "    simulations = np.append(simulations, stat)\n",
    "print(simulations[:5])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "You are multiplying by 100 because sample.item(0) represents a proportion (a value between 0 and 1),\n",
    "and you want to express it as a percentage.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** \n",
    "\n",
    "\n",
    "Question 2.7. Simulate 10,000 values of the test statistic \n",
    "\n",
    "Use as many lines of code as you need. We have included the code that visualizes the distribution of the simulated values. The red dot represents the observed statistic you found in Question 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Incorrect code \n",
    "import ploty as plt \n",
    "\n",
    "observed_statistic = ...\n",
    "def one_simulated_statistic():    \n",
    "    simulated_statistics = make_array()\n",
    "    num_simulations = 10000\n",
    "\n",
    "    for i in range(num_simulations):\n",
    "        sample = sample_proportions(sample_size, percent_V1)\n",
    "        percent = sample.item(0) * 100 # percent is calculated here\n",
    "        simulated_statistics = np.append(simulated_statistics, percent)\n",
    "    return one_simulated_statistics\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def one_simulated_statistic():\n",
    "    sample_size = 50\n",
    "    null_probs = [0.5, 0.5]\n",
    "    sample = sample_proportions(sample_size, null_probs)\n",
    "    percent = sample.item(0) * 100\n",
    "    return percent - 50\n",
    "\n",
    "simulated_statistics = make_array()\n",
    "num_simulations = 10000\n",
    "for i in range(num_simulations):\n",
    "    stat = one_simulated_statistic()\n",
    "    simulated_statistics = np.append(simulated_statistics, stat)\n",
    "\n",
    "# Plot\n",
    "Table().with_columns('Simulated Statistic', simulated_statistics).hist()\n",
    "plt.scatter(10, -0.002, color='red', s=40)  # Observed stat = 10\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.3.7 Conventional Cut-Offs and P Value**\n",
    "notes:\n",
    "*Trials is the amount of times it is tested* \n",
    "- If you don’t want to use your own judgment, use np.count_nonzero(distances >= different_observed_statistic) / trials \n",
    "- np.count_nonzero() function counts how many values in an array satisfy a certain condition\n",
    "`p_value = np.count_nonzero(simulations >= observed_test_statistic) / testing_number` # simulations is an array\n",
    "\n",
    "The conventions are based on the area in the tail, starting at the observed statistic (the red dot) and looking in the direction that makes us lean toward the alternative. In this example that’s the right side, because big distances favor the alternative which says that the model isn’t good.\n",
    "\n",
    "**<center>if the area of the tail is small, the observed statistic is far away from the values most commonly predicted by the null hypothesis.</center>**\n",
    "\n",
    "- Remember that in a histogram, area represents percent. To find the area in the tail, we have to find the percent of distances that were greater than or equal to 3.2, where the red dot is. The array distances contains the averages for all 10,000 repetitions of random sampling under Mendel’s model, and different_observed_statistic is 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[11. 2 Total Variation Distance](https://inferentialthinking.com/chapters/11/2/Multiple_Categories.html#a-new-statistic-the-distance-between-two-distributions)** \n",
    "\n",
    "notes: \n",
    "- where() doesn’t extract values—use .column() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code for calculating TVD \n",
    "\n",
    "def total_variation_distance(distribution_1, distribution_2):\n",
    "    \"\"\"The function total_variation_distance takes two arrays containing the distributions to compare, and returns the TVD between them.\"\"\"\n",
    "    return sum(np.abs(distribution_1 - distribution_2)) / 2\n",
    "\n",
    "# Simulate one simulated value of \n",
    "# the total variation distance between\n",
    "# the distribution of a sample selected at random\n",
    "# and the distribution of the eligible population\n",
    "\n",
    "def one_simulated_tvd():\n",
    "    sample_distribution = sample_proportions(1453, eligible_population)\n",
    "    return total_variation_distance(sample_distribution, eligible_population)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>Putting into practice</center>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16666667  0.16666667  0.16666667  0.16666667  0.16666667  0.16666667]\n"
     ]
    }
   ],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "null_distribution = make_array(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)\n",
    "print(null_distribution)  # [0.1667, 0.1667, ...]\n",
    "\n",
    "def calculate_tvd(null_dist, obs_dist):\n",
    "    return sum(np.abs(null_dist - obs_dist)) / 2\n",
    "\n",
    "# Observed data from a table (imagine a column 'Counts')\n",
    "die_table = Table().with_columns('Counts', [1200, 1100, 950, 900, 850, 1000])\n",
    "obs_dist = die_table.column('Counts') / 6000 # get proportions from tables array ## column lets you extract the data \n",
    "calculate_tvd(null_distribution, obs_dist)\n",
    "\n",
    "observed_total_variation_distance = 0.050000000000000003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an array called simulated_tvds that contains 10,000 simulated values under the null hypothesis. Assume that the original sample consisted of 1,000 individuals.** \n",
    "\n",
    "notes: \n",
    "- you need to make an empty array\n",
    "- use sample_proportions\n",
    "- create a for loop with range(10000) simulated values, sample_size consists of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03133333  0.02833333  0.04933333  0.02833333  0.009     ]\n"
     ]
    }
   ],
   "source": [
    "simulated_tvds = make_array()\n",
    "\n",
    "for i in range(10000): \n",
    "    sample = sample_proportions(1000, null_distribution)\n",
    "    tvd = calculate_tvd(sample, null_distribution) \n",
    "    simulated_tvds = np.append(simulated_tvds, tvd) \n",
    "    \n",
    "print(simulated_tvds[:5]) # different output: print(simulated_tvds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "job_pref = Table().with_columns(\n",
    "    'Preference', ['SE', 'OSNT', 'SE', 'OSNT', 'SE', 'OSNT'], # count of 3 SE, and 3 OSNT \n",
    "    'Gender', ['male', 'female', 'female', 'male', 'female', 'female']\n",
    ")\n",
    "\n",
    "se_job_preference = job_pref.group('Preference').where('Preference', 'SE').column('count').item(0)\n",
    "print(se_job_preference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: **The data scientists want to use the data to test whether males are older than females. One of the following statements is their null hypothesis and another is their alternative hypothesis. Assign null_statement_number and alternative_statement_number to the numbers of the correct statements in the code cell below.**\n",
    "\n",
    "Options:\n",
    "1. In the sample, the males and females have the same distribution of ages; the sample averages of the two groups are different due to chance.\n",
    "    - This is evaluating a sample, not applying to the population. Thus it is not correct option\n",
    "2. In the population, the males and females have the same distribution of ages; the sample averages of the two groups are different due to chance.\n",
    "    - This statement is a correct null hypothesis, that we want to prove wrong\n",
    "3. The age distributions of males and females in the population are different due to chance.\n",
    "    - This is not stating the purpose of the test, False\n",
    "4. The males in the sample are older than the females, on average.\n",
    "    - Sample, not population --> False\n",
    "5. The males in the population are older than the females, on average.\n",
    "    - Correct statement for alternative hypothesis \n",
    "6. The average ages of the males and females in the population are different.\n",
    "    - Incorrect statement because thats not what we are testing for \n",
    "\n",
    "Question: \n",
    "- _**Is there formality, where the null must be what we are trying to prove wrong, and the alternative is what we are testing for in the data**_\n",
    "\n",
    "    Null: \n",
    "    - Definition: The null is the \"default\" or \"no effect\" statement—typically what you’re trying to disprove or reject. It assumes no difference, no relationship, or equality in the population, with any observed differences in the sample attributed to random chance.\n",
    "        - Role: It’s the baseline you test against. You aim to gather evidence to reject it (or fail to reject it).\n",
    "\n",
    "    Alternative: \n",
    "    - Definition: The alternative is what you’re testing for—the claim of a difference, effect, or relationship in the population. It’s what you suspect or hope the data supports.\n",
    "\n",
    "\n",
    "\n",
    "Question: **The data scientists have decided to use a permutation test. Assign permutation_test_reason to the number corresponding to the reason they made this choice. (4 points)\n",
    "1. Since a person's age shouldn't be related to their gender, it doesn't matter who is labeled \"male\" and who is labeled \"female\", so you can use permutations.\n",
    "2. Under the null hypothesis, permuting the labels in the sampled_ages table is equivalent to drawing a new random sample with the same number of males and females as in the original sample.\n",
    "3. Under the null hypothesis, permuting the rows of sampled_ages table is equivalent to drawing a new random sample with the same number of males and females as in the original sample.**\n",
    "\n",
    "notes: \n",
    "- [Reading](https://inferentialthinking.com/chapters/12/1/AB_Testing.html#permutation-test)\n",
    "- [Final Review](https://www.data8.org/data8assets/exam/stats_final_review.pdf)\n",
    "- To determine if two samples come from the same underlying distribution. Or, to see if\n",
    "the distribution of some feature/attribute for one class is the same as the distribution of the\n",
    "feature/attribute for another class (in the population). These questions are answered by\n",
    "permutation tests:\n",
    "    - A permutation test shuffles your data randomly to see if the difference you observe (e.g., males older than females) could happen by chance. It’s like mixing up names in a hat and checking if the result still looks special.\n",
    "\n",
    "\n",
    "\n",
    "Question: **Question 4.4. The data scientists have decided to use a permutation test. Assign permutation_test_reason to the number corresponding to the reason they made this choice. (4 points)**\n",
    "\n",
    "1. Since a person's age shouldn't be related to their gender, it doesn't matter who is labeled \"male\" and who is labeled \"female\", so you can use permutations.\n",
    "    - You are supposed to change the labels, BUT, it need sto be the same number of labels for it to be the same test\n",
    "2. Under the null hypothesis, permuting the labels in the sampled_ages table is equivalent to drawing a new random sample with the same number of males and females as in the original sample.\n",
    "    - This is the correct option because we use the same number of males/females, but switch the labeling\n",
    "3. Under the null hypothesis, permuting the rows of sampled_ages table is equivalent to drawing a new random sample with the same number of males and females as in the original sample.\n",
    "    - This changes the rows values, which is an entirely different test with a different outcome, thus is not correct\n",
    "\n",
    "**Question 4.6. Complete the cell below so that observed_statistic_ab evaluates to the observed value of the data scientists' test statistic. Use as many lines of code as you need, and remember that you can use any quantity, table, or array that you created earlier. (4 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Preference</th> <th>Age</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>cat       </td> <td>5   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dog       </td> <td>3   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>cat       </td> <td>2   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dog       </td> <td>7   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>cat       </td> <td>4   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Full table:\n",
    "Gender | Age mean\n",
    "female | 42.0692\n",
    "male   | 43.3833\n",
    "\n",
    "Row values:\n",
    " ['female' 'male'] \n",
    "\n",
    " Age Mean Row: \n",
    "[ 42.06923077  43.38333333]\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "group_mean_tbl = sampled_ages.group('Gender', np.mean)\n",
    "\n",
    "print(f'Full table:\\n{group_mean_tbl}\\n\\nRow values/labels:\\n {group_mean_tbl[0]} \\n\\n Age Mean Row: \\n{group_mean_tbl[1]}')\n",
    "\n",
    "\n",
    "print(f'Female mean: {group_mean_tbl[1].item(0)}')\n",
    "print(f'Male mean: {group_mean_tbl[1].item(1)}')\n",
    "\n",
    "\n",
    "group_means = group_mean_tbl.column('Age mean')      # array of mean ages\n",
    "avg_male_vs_female = group_means[0] > group_means[1]\n",
    "print(f'\\nEvaluates to: {avg_male_vs_female}')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from datascience import *\n",
    "\n",
    "pet_ages = Table().with_columns(\n",
    "    'Preference', ['cat', 'dog', 'cat', 'dog', 'cat'],\n",
    "    'Age', [5, 3, 2, 7, 4]\n",
    ")\n",
    "\n",
    "pet_ages.show()\n",
    "\n",
    "cat_ages = pet_ages.where('Preference', 'cat').column('Age')\n",
    "dog_ages = pet_ages.where('Preference', 'dog').column('Age')\n",
    "observed_statistic_ab = dog_ages.mean() - cat_ages.mean()\n",
    "print(observed_statistic_ab)  # Output: 1.0 (5 - 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffled Labels Section**\n",
    "\n",
    "```\n",
    "shuffled_labels = smoking_and_birthweight.sample(with_replacement = False).column(0)\n",
    "original_and_shuffled = smoking_and_birthweight.with_column('Shuffled Label', shuffled_labels)\n",
    "\n",
    "```\n",
    "What it does:\n",
    "- **Return a new table where k rows are randomly sampled from the original table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog' 'cat' 'dog' 'cat' 'cat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nArguments: \\n\\nk -- specifies the number of rows (int) to be sampled from the table. Default is k equal to number of rows in the table.\\n\\nwith_replacement -- (bool) By default True; usually set to False \\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_labels = pet_ages.sample(with_replacement = False).column(0) \n",
    "print(shuffled_labels)\n",
    "\"\"\"\n",
    "Arguments: \n",
    "\n",
    "k -- specifies the number of rows (int) to be sampled from the table. Default is k equal to number of rows in the table.\n",
    "\n",
    "with_replacement -- (bool) By default True; usually set to False \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulated_statistic():    \n",
    "    null_probs = [0.6635220125786163, 0.33647798742138363] # sums to 1 \n",
    "    sample = sample_proportions(sample_size, null_probs)\n",
    "    percent = sample.item(0) * 100 # percent is calculated here before subtraction \n",
    "    stat = percent - 60\n",
    "    return stat \n",
    "\n",
    "simulated_statistics = make_array()\n",
    "num_simulations = 10000\n",
    "\n",
    "for i in range(num_simulations): \n",
    "    stat = one_simulated_statistic()\n",
    "    simulated_statistics = np.append(simulated_statistics, stat) \n",
    "\n",
    "def one_simulated_difference_of_means():\n",
    "    \"\"\"Returns: Difference between mean birthweights\n",
    "    of babies of smokers and non-smokers after shuffling labels\"\"\"\n",
    "    \n",
    "    # array of shuffled labels\n",
    "    shuffled_labels = births.sample(with_replacement=False).column('Maternal Smoker')\n",
    "    \n",
    "    # table of birth weights and shuffled labels\n",
    "    shuffled_table = births.select('Birth Weight').with_column(\n",
    "        'Shuffled Label', shuffled_labels)\n",
    "    \n",
    "    return difference_of_means(shuffled_table, 'Shuffled Label')   \n",
    "\n",
    "def difference_of_means(table, group_label):\n",
    "    \"\"\"Takes: name of table,\n",
    "    column label that indicates the group to which the row belongs\n",
    "    Returns: Difference of mean birth weights of the two groups\"\"\"\n",
    "    reduced = table.select('Birth Weight', group_label)\n",
    "    means_table = reduced.group(group_label, np.average)\n",
    "    means = means_table.column(1)\n",
    "    return means.item(1) - means.item(0)\n",
    "\n",
    "\n",
    "difference_of_means(births, 'Maternal Smoker')\n",
    "\n",
    "\n",
    "female_mean = group_mean_tbl[1].item(0)\n",
    "male_mean = group_mean_tbl[1].item(1)\n",
    "observed_statistic_ab = male_mean - female_mean\n",
    "observed_statistic_ab\n",
    "\n",
    "\n",
    "### correct example\n",
    "from datascience import *\n",
    "\n",
    "pet_ages = Table().with_columns(\n",
    "    'Preference', ['cat', 'dog', 'cat', 'dog', 'cat'],\n",
    "    'Age', [5, 3, 2, 7, 4]\n",
    ")\n",
    "\n",
    "def simulate_one_statistic():\n",
    "    \"Returns one simulated dog mean - cat mean\"\n",
    "    shuffled_labels = pet_ages.sample(with_replacement=False).column('Preference')  # Shuffle labels\n",
    "    shuffled_tbl = pet_ages.with_columns('Preference', shuffled_labels)  # Keep original ages\n",
    "    cat_mean = shuffled_tbl.where('Preference', 'cat').column('Age').mean()\n",
    "    dog_mean = shuffled_tbl.where('Preference', 'dog').column('Age').mean()\n",
    "    return dog_mean - cat_mean\n",
    "\n",
    "print(simulate_one_statistic())  # E.g., -0.5, 1.0, etc. \n",
    "\n",
    "\n",
    "differences = make_array()\n",
    "\n",
    "repetitions = 5000\n",
    "for i in np.arange(repetitions):\n",
    "    new_difference = one_simulated_difference_of_means()\n",
    "    differences = np.append(differences, new_difference)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: **Question 4.10. Complete the cell to simulate 5,000 values of the statistic. We have included the code that draws the empirical distribution of the statistic and shows the value of observed_statistic_ab from Question 3.6. Feel free to use as many lines of code as you need. (3 points)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example from textbook 12.1\n",
    "\n",
    "simulated_statistics_ab = make_array()\n",
    "reps = 5000\n",
    "for i in np.arange(reps): \n",
    "    new_diff = simulate_one_statistic() \n",
    "    simulated_statistics_ab = np.append(simulated_statistics_ab, new_diff)\n",
    "\n",
    "# Do not change these lines\n",
    "Table().with_columns('Simulated Statistic', simulated_statistics_ab).hist()\n",
    "plt.scatter(observed_statistic_ab, -0.002, color='red', s=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question**Question 4.11. Use the simulation to find an empirical approximation to the p-value. Assign p_val to the appropriate p-value from this simulation. Then, assign conclusion to either null_hyp or alt_hyp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = np.count_nonzero(simulated_statistics_ab >= observed_statistic_ab) / 5000\n",
    "\n",
    "### always remember that np.count_nonzero is used to simulate p_val with array of simulated values, greater than or equal to the observed test statistic "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
